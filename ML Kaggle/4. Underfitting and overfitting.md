## Experimenting with different models

Now that we can measure model accuracy, we can experiment with alternative models and see which ones give the best results. We can see in Scikit learn's [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) has many options one of which is to decide tree's depth i.e. how many splits it makes before coming to a prediction.

* As the tree gets deeper, dataset gets sliced up into leaves with fewer houses. for example, at 10th split there would be 1024 groups of houses.

![R3ywQsR](https://user-images.githubusercontent.com/62146744/78992192-544ea480-7b58-11ea-9924-10f1b42330dd.png)


* **Overfitting** - If we divide houses in many leaves, we have fewer houses in each leaf. So now our prediction would be quite close to home's actual values but it would perform poor for new data as each prediction is based only on a few houses.

* **Underfitting** - On the other hand let us say we divide only in 2-4 leafs, predictions may be far off, even for the training data as each group has a wide variety of houses. So when a model fails to capture important distinction in model , it performs poorly even in the training set, that is called underfitting.

* So our goal is to find that sweet spot between overfitting and underfitting where the error is minimum. Visually, we want the low point of the red validation curve.

![2q85n9s](https://user-images.githubusercontent.com/62146744/78992086-18b3da80-7b58-11ea-9f6c-e840979ecefb.png)

## Example

We have a few alternatives for controlling tree-depth and many allow some routes throught he tree to have greater depth than other routes.

<br>

The **max_leaf_nodes** argument gives us a way to control overfitting vs underfitting. The more leaves we allow the model to make, more we move from underfiiting to overfitting.

<br>

We can then use a utility functio to compare MAE values from different values of max_leaf_nodes

```python

from sklearn.tree import DecisionTreeRegressor()
from sklearn.metrics import mean_absolute_error

def get_mae( max_leaf_nodes, train_X, val_X, train_y, val_y )
    model = DecisionTreeRegressor( max_leaf_nodes = max_leaf_nodes, random_state = 0 )
    model.fit ( train_X, train_y)
    pred_val = model.predict( val_X )
    mae = mean_absolute_error( val_y, pred_val )
    return(mae)
    
```

Thus our function is defined, now we can use for loop to compare mae of models with different max_leaf_nodes.

```python

for max_leaf_nodes in [5, 50, 500, 5000]
    my_mae = get_mae( max_leaf_nodes, train_X, val_X, train_y, val_y )
    print("Max leaf nodes : %d \t\t Mean Absolute Error: %d" %(max_leaf_nodes, my_mae))  #train_X, train_y, val_X, val_y were already loaded
    
output - 

Max leaf nodes: 5  		 Mean Absolute Error:  347380
Max leaf nodes: 50  		 Mean Absolute Error:  258171
Max leaf nodes: 500  		 Mean Absolute Error:  243495
Max leaf nodes: 5000  		 Mean Absolute Error:  254983
```

So, out of options given, 500 is the most optimum number of leaf nodes.

## Conclusion

* **Overfitting** - capturing spurious patterns that won't recur in the future, leading to less accurate predictions.
* **Underfitting** - failing to capture relevant patterns, again leading to less accurate predictions.

We use validation data to measure a model's accuracy.

























































